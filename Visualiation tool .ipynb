{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da7dfa3",
   "metadata": {},
   "source": [
    "# Visualisation for MLP32 on CMNIST\n",
    "- vanilla\n",
    "- DebiAN\n",
    "- DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2976116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import captum\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "\n",
    "\n",
    "from DebiAN.models.simple_cls import MLP\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from data.utils import get_dataset, IdxDataset\n",
    "from module.util import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04a4b2",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae7eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "def overlay(input, cam, alpha=0.9, colormap=\"jet\"):\n",
    "    # inspired by https://github.com/frgfm/torch-cam/blob/master/torchcam/utils.py\n",
    "\n",
    "    img = transforms.ToPILImage()(input)\n",
    "    # normalize to 0,1\n",
    "    cam -= torch.min(cam)\n",
    "    cam /= torch.max(cam)\n",
    "    cam_img = transforms.ToPILImage(mode='F')(cam)\n",
    "\n",
    "    if type(colormap) is str:\n",
    "        cmap = cm.get_cmap(colormap)\n",
    "    else:\n",
    "        cmap = colormap\n",
    "\n",
    "    # Resize mask and apply colormap\n",
    "    overlay_raw = cam_img.resize(img.size, resample=Image.BILINEAR)\n",
    "    overlay_raw = cam_img.resize(img.size, resample=Image.NEAREST)\n",
    "    overlay = overlay_raw\n",
    "    overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, :3]).astype(np.uint8)\n",
    "    # Overlay the image with the mask\n",
    "    overlayed_img = Image.fromarray((alpha * np.asarray(img) + (1 - alpha) * overlay).astype(np.uint8))\n",
    "    return overlayed_img\n",
    "\n",
    "\n",
    "def attribute_image_features(net,algorithm, input,label, **kwargs):\n",
    "    net.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(input,\n",
    "                                              target=label,\n",
    "                                              **kwargs\n",
    "                                             )\n",
    "    return tensor_attributions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e16d9",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71b6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'Results/cmnist' OK\n"
     ]
    }
   ],
   "source": [
    "#CMNIST\n",
    "data_path  ='data/'\n",
    "split='test'\n",
    "percent='5pct'\n",
    "\n",
    "result_path  ='Results/cmnist'\n",
    "os.makedirs(result_path, exist_ok = True)\n",
    "print(\"Directory '%s' OK\" %result_path)\n",
    "\n",
    "#Models and xai methods\n",
    "models_type=['vanilla','DebiAN','DFA']\n",
    "Saliency_methods=['integrated_gradient','smoothgrad','deeplift']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fd6c1",
   "metadata": {},
   "source": [
    "# LOAD DB CMNIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfce6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 samples in test CMNST\n"
     ]
    }
   ],
   "source": [
    "dataset=get_dataset('cmnist',\n",
    "        data_dir=data_path,\n",
    "        dataset_split=split,\n",
    "        transform_split=\"valid\",\n",
    "        percent=percent)\n",
    "\n",
    "if dataset.__len__()==0:\n",
    "    print('Error - data not loaded')\n",
    "else: \n",
    "    print ('{} samples in {} CMNST'.format(dataset.__len__(),split))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb15a64",
   "metadata": {},
   "source": [
    "# LOAD MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528053a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla\n",
      "MLP(\n",
      "  (feature): Sequential(\n",
      "    (0): Linear(in_features=2352, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=32, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "DebiAN\n",
      "MLP(\n",
      "  (feature): Sequential(\n",
      "    (0): Linear(in_features=2352, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=32, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "DFA\n",
      "MLP_DISENTANGLE(\n",
      "  (feature): Sequential(\n",
      "    (0): Linear(in_features=2352, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=32, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models=dict()\n",
    "col_names=[]\n",
    "col_names.append('id')\n",
    "col_names.append('gt')\n",
    "col_names.append('bias')\n",
    "col_names.append('bias_label')\n",
    "for m in models_type:\n",
    "    print(m)\n",
    "    \n",
    "     \n",
    "    if m=='DFA':\n",
    "        model = get_model('mlp_DISENTANGLE', 10)   \n",
    "        \n",
    "        model_path =\"ckpt/models_cmnist_LDD/no_dec/{}/best_model_l.th\".format(percent)      \n",
    "        state_dict = torch.load(model_path)\n",
    "        model.load_state_dict(state_dict['state_dict'])\n",
    "        model = model.eval()\n",
    "        models[m+'_l']=model\n",
    "        \n",
    "        model_path =\"ckpt/models_cmnist_LDD/no_dec/{}/best_model_b.th\".format(percent)      \n",
    "        state_dict = torch.load(model_path)\n",
    "        model.load_state_dict(state_dict['state_dict'])\n",
    "        model = model.eval()\n",
    "        models[m+'_b']=model\n",
    "        \n",
    "        print(model)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if m=='vanilla':\n",
    "            model_path =\"ckpt/cmnist/cmnist_{}_{}.th\".format(percent,m)  \n",
    "            model=MLP(last_hidden_layer=32)\n",
    "            state_dict = torch.load(model_path)\n",
    "            model.load_state_dict(state_dict['state_dict'])\n",
    "        if m=='DebiAN':\n",
    "            model_path =\"ckpt/cmnist/cmnist_{}_{}.th\".format(percent,m)  \n",
    "            model=MLP(last_hidden_layer=32)\n",
    "            state_dict = torch.load(model_path)\n",
    "            model.load_state_dict(state_dict['model'])  \n",
    "        if m=='DebiAN100':\n",
    "            model_path =\"ckpt/cmnist/cmnist_{}_mlp100_DebiAN.th\".format(percent,m)  \n",
    "            model=MLP(last_hidden_layer=100)\n",
    "            state_dict = torch.load(model_path)\n",
    "            model.load_state_dict(state_dict['model'])   \n",
    "        model = model.eval()\n",
    "        print(model)\n",
    "        models[m]=model\n",
    "  \n",
    "    col_names.append('pred_{}'.format(m))\n",
    "    col_names.append('correct_{}'.format(m))\n",
    "    col_names.append('prob_{}'.format(m))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08e1ef",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c028621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:30<00:00, 327.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(columns=col_names) \n",
    "for idx_img in tqdm(range(len(dataset))):\n",
    "    new_row = dict.fromkeys(col_names, 0)   \n",
    "    image,label,idx = dataset[idx_img]\n",
    "    l_target,l_bias=label\n",
    "    l_target=l_target.item()\n",
    "    l_bias=l_bias.item()\n",
    "    x=torch.unsqueeze(image, 0)\n",
    "    new_row['id']=idx_img\n",
    "    new_row['gt']=l_target\n",
    "    new_row['bias_label']=l_bias\n",
    "    bias=0\n",
    "    if l_bias==l_target:\n",
    "        bias=1      \n",
    "    new_row['bias']=bias \n",
    "    for m in models_type:\n",
    "        if m=='DFA':\n",
    "            x=x.view(-1, 3*28*28)\n",
    "            l1=models[m+'_l'].extract(x)  \n",
    "            l2=models[m+'_b'].extract(x)  \n",
    "            #logits=models[m+'_l'].fc(torch.hstack((l1,l2)))\n",
    "            \n",
    "            indices = np.random.permutation(l2.size(0))\n",
    "            l2_swap = l2[indices]  # z tilde\n",
    "            z = torch.cat((l1, l2_swap), dim=1)\n",
    "            logits=models[m+'_l'].fc(z)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            logits=models[m](x)\n",
    "        pred = logits.data.max(1, keepdim=True)[1].squeeze(1)  \n",
    "        new_row['pred_{}'.format(m)]=pred.item()\n",
    "        new_row['prob_{}'.format(m)]= torch.max(F.softmax(logits, 1)).item()\n",
    "        correct=0\n",
    "        if pred==l_target:\n",
    "            correct=1\n",
    "        new_row['correct_{}'.format(m)]=correct\n",
    "        new_df = pd.DataFrame([new_row], columns=col_names)\n",
    "    df = pd.concat([new_df, df], ignore_index = True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdb59247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2352])\n"
     ]
    }
   ],
   "source": [
    "x=x.view(-1, 3*28*28)\n",
    "l1=models['DFA_l'].extract(x)\n",
    "l2=models['DFA_b'].extract(x)\n",
    "#logits=models['DFA'].fc(logitorch)\n",
    "l=torch.hstack((l2,l1))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6001cf",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a608023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id gt bias bias_label pred_vanilla correct_vanilla  prob_vanilla  \\\n",
      "0  9999  6    0          1            6               1      0.978583   \n",
      "1  9998  6    0          4            6               1      1.000000   \n",
      "2  9997  6    0          8            8               0      1.000000   \n",
      "3  9996  6    0          0            6               1      1.000000   \n",
      "4  9995  6    0          0            6               1      1.000000   \n",
      "\n",
      "  pred_DebiAN correct_DebiAN  prob_DebiAN pred_DFA correct_DFA  prob_DFA  \n",
      "0           2              0     0.995706        0           0       1.0  \n",
      "1           6              1     0.813954        4           0       1.0  \n",
      "2           2              0     0.654117        8           0       1.0  \n",
      "3           6              1     0.999996        0           0       1.0  \n",
      "4           6              1     0.999645        8           0       1.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5d39c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20569268401156326"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.306\n",
    "0.2854\n",
    "0.9990059642147118\n",
    "0.9980119284294234\n",
    "0.22848565710473648\n",
    "0.20569268401156326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48eb8239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675\n",
      "0.7189\n",
      "0.3477\n",
      "0.9930417495029821\n",
      "0.989065606361829\n",
      "0.9652087475149106\n",
      "0.7422726261952413\n",
      "0.688681343117634\n",
      "0.2786301979097176\n"
     ]
    }
   ],
   "source": [
    "conflict_df=df[df.bias==0]\n",
    "align_df=df[df.bias==1]\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "acc_vanilla=df['correct_vanilla'].sum()/len(df)\n",
    "acc_DebiAN=df['correct_DebiAN'].sum()/len(df)\n",
    "acc_DebiAN100=df['correct_DFA'].sum()/len(df)\n",
    "print(acc_vanilla)\n",
    "print(acc_DebiAN)\n",
    "print(acc_DebiAN100)\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy align-bias data\n",
    "align_acc_vanilla=align_df['correct_vanilla'].sum()/len(align_df)\n",
    "align_acc_DebiAN=align_df['correct_DebiAN'].sum()/len(align_df)\n",
    "align_acc_DebiAN100=align_df['correct_DFA'].sum()/len(align_df)\n",
    "print(align_acc_vanilla)\n",
    "print(align_acc_DebiAN)\n",
    "print(align_acc_DebiAN100)\n",
    "\n",
    "# Accuracy conflict-bias data\n",
    "conflict_acc_vanilla=conflict_df['correct_vanilla'].sum()/len(conflict_df)\n",
    "conflict_acc_DebiAN=conflict_df['correct_DebiAN'].sum()/len(conflict_df)\n",
    "conflict_acc_DebiAN100=conflict_df['correct_DFA'].sum()/len(conflict_df)\n",
    "print(conflict_acc_vanilla)\n",
    "print(conflict_acc_DebiAN)\n",
    "print(conflict_acc_DebiAN100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e6e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4de9d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.688681343117634"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7675\n",
    "0.7189\n",
    "0.9930417495029821\n",
    "0.989065606361829\n",
    "0.7422726261952413\n",
    "0.688681343117634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dde87078",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_model=df.correct_vanilla==df.correct_DebiAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9d8699d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (555308734.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_211076/555308734.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    acc_allign_bias_vanilla=\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "acc_vanilla=df[df.correct_vanilla].count()/len(df)\n",
    "acc_allign_bias_vanilla=\n",
    "acc_conflict_bias_vanilla=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae93c6",
   "metadata": {},
   "source": [
    "# Visualize prediction Biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb475a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b=df[(df.correct_vanilla==0)&(df.correct_DebiAN==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx=5623\n",
    "image,label,idx = dataset[image_idx]\n",
    "x=torch.unsqueeze(image, 0)\n",
    "image=torch.squeeze(image,0)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated Gradient\n",
    "ig = IntegratedGradients(model)\n",
    "attr_ig, delta = attribute_image_features(model,ig, x,l_target, baselines=x * 0, return_convergence_delta=True)\n",
    "attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "print('Approximation delta: ', abs(delta))\n",
    "\n",
    "# Integrated Gradient with Smoothgrad\n",
    "ig = IntegratedGradients(model)\n",
    "nt = NoiseTunnel(ig)\n",
    "attr_ig_nt = attribute_image_features(model,nt,x,l_target, baselines=x * 0, nt_type='smoothgrad_sq',\n",
    "                                      nt_samples=100, stdevs=0.2)\n",
    "attr_ig_nt = np.transpose(attr_ig_nt.squeeze(0).cpu().detach().numpy(), (1, 2, 0))\n",
    "#DeepLift\n",
    "dl = DeepLift(model)\n",
    "attr_dl = attribute_image_features(model,dl, x,l_target,baselines=x * 0)\n",
    "attr_dl = np.transpose(attr_dl.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78627633",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = np.transpose((image.cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "\n",
    "_ = viz.visualize_image_attr(None, original_image, \n",
    "                      method=\"original_image\", title=\"Original Image\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_ig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
    "                          show_colorbar=True, title=\"Overlayed Integrated Gradients\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_ig_nt, original_image, method=\"blended_heat_map\", sign=\"absolute_value\", \n",
    "                             outlier_perc=10, show_colorbar=True, \n",
    "                             title=\"Overlayed Integrated Gradients \\n with SmoothGrad Squared\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_dl, original_image, method=\"blended_heat_map\",sign=\"all\",show_colorbar=True, \n",
    "                          title=\"Overlayed DeepLift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_ig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef735f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
